import streamlit as st
import numpy as np
import matplotlib.pyplot as plt

def mostrar():
    st.markdown('<h2 class="section-header">Backpropagation: Um Passo de Cada Vez</h2>', unsafe_allow_html=True)
    st.markdown("""O Backpropagation pode parecer uma "caixa preta". Vamos abri-la e executar um Ãºnico passo de treinamento de forma interativa. Veremos exatamente como a rede usa o erro para descobrir como ajustar seus pesos.\n\nNosso cenÃ¡rio: uma rede com **1 neurÃ´nio**, **2 entradas**, e funÃ§Ã£o de ativaÃ§Ã£o **Sigmoid**.""")
    col1, col2 = st.columns([1,1.2])
    with col1:
        st.subheader("âš™ï¸ Controles"); learning_rate = st.slider("Taxa de Aprendizado (Î·)",.01,1.,.5,.01)
        if 'bp_step' not in st.session_state: st.session_state.bp_step = 0
        def next_step(): st.session_state.bp_step += 1
        def reset_steps(): st.session_state.bp_step,st.session_state.w1,st.session_state.w2,st.session_state.bias=0,.3,-.5,.1
        if 'w1' not in st.session_state: reset_steps()
        c1,c2=st.columns(2);c1.button("PrÃ³ximo Passo âž¡ï¸",on_click=next_step,type="primary",use_container_width=True);c2.button("Reiniciar ðŸ”„",on_click=reset_steps,use_container_width=True)
        x=np.array([2.,3.]);y_real=1.;w=np.array([st.session_state.w1,st.session_state.w2]);bias=st.session_state.bias
    with col2:
        st.subheader("VisualizaÃ§Ã£o da Descida do Gradiente");w_space=np.linspace(-1,1,100);error_space=(w_space-.7)**2
        fig,ax=plt.subplots();ax.plot(w_space,error_space,label="SuperfÃ­cie de Erro");ax.set_xlabel("Valor do Peso (Ex: w1)");ax.set_ylabel("Erro");ax.set_title("O Objetivo: Atingir o MÃ­nimo do Erro");ax.plot(st.session_state.w1,(st.session_state.w1-.7)**2,'ro',markersize=10,label="Peso Atual")
        if st.session_state.bp_step>=5:
            w_novo_calculado = w[0]-learning_rate*st.session_state.grad_w1
            ax.plot(w_novo_calculado,(w_novo_calculado-.7)**2,'go',markersize=10,label="Peso Novo")
            ax.annotate("",xy=(w_novo_calculado,(w_novo_calculado-.7)**2),xytext=(st.session_state.w1,(st.session_state.w1-.7)**2),arrowprops=dict(arrowstyle="->",color="purple",lw=2))
        ax.legend();st.pyplot(fig)
    st.markdown("---"); st.subheader("ðŸ” O Processo Detalhado"); st.markdown("##### ðŸ Estado Inicial"); st.markdown(f"- **Entradas:** `xâ‚ = {x[0]}`, `xâ‚‚ = {x[1]}`\n- **Alvo Real:** `y_real = {y_real}`\n- **Pesos Iniciais:** `wâ‚ = {w[0]:.2f}`, `wâ‚‚ = {w[1]:.2f}`\n- **Bias Inicial:** `b = {bias:.2f}`")
    if st.session_state.bp_step>=1:
        with st.container(border=True):
            st.markdown("##### Passo 1: Forward Pass - Calcular a PrediÃ§Ã£o da Rede");z=np.dot(w,x)+bias;predicao=1/(1+np.exp(-z))
            st.latex(r"z=(wâ‚\times xâ‚)+(wâ‚‚\times xâ‚‚)+b");st.markdown(f"`z=({w[0]:.2f}Ã—{x[0]})+({w[1]:.2f}Ã—{x[1]})+{bias:.2f}={z:.4f}`")
            st.latex(r"\text{prediÃ§Ã£o (a)}=\sigma(z)=\frac{1}{1+e^{-z}}");st.markdown(f"`prediÃ§Ã£o = Ïƒ({z:.4f})={predicao:.4f}`")
            st.session_state.predicao,st.session_state.z=predicao,z
    if st.session_state.bp_step>=2:
        with st.container(border=True):
            st.markdown("##### Passo 2: Calcular o Erro da PrediÃ§Ã£o");erro=.5*(y_real-st.session_state.predicao)**2
            st.latex(r"E=\frac{1}{2}(y_{real}-\text{prediÃ§Ã£o})^2");st.markdown(f"`E=0.5*({y_real}-{st.session_state.predicao:.4f})Â²={erro:.4f}`")
    if st.session_state.bp_step>=3:
        with st.container(border=True):
            st.markdown("##### Passo 3: Backward Pass - Calcular os Gradientes (A MÃ¡gica da Regra da Cadeia)");st.info("O objetivo Ã© descobrir a contribuiÃ§Ã£o de cada peso para o erro. Usamos a Regra da Cadeia do cÃ¡lculo: `âˆ‚E/âˆ‚w=(âˆ‚E/âˆ‚prediÃ§Ã£o)*(âˆ‚prediÃ§Ã£o/âˆ‚z)*(âˆ‚z/âˆ‚w)`")
            dE_dpred,dpred_dz=st.session_state.predicao-y_real,st.session_state.predicao*(1-st.session_state.predicao)
            st.markdown("**Componentes do Gradiente:**");st.markdown(f"- `âˆ‚E/âˆ‚prediÃ§Ã£o=prediÃ§Ã£o-y_real={dE_dpred:.4f}`");st.markdown(f"- `âˆ‚prediÃ§Ã£o/âˆ‚z=Ïƒ(z)*(1-Ïƒ(z))={dpred_dz:.4f}`");st.markdown(f"- `âˆ‚z/âˆ‚wâ‚=xâ‚={x[0]}`")
            st.session_state.dE_dpred,st.session_state.dpred_dz=dE_dpred,dpred_dz
    if st.session_state.bp_step>=4:
        with st.container(border=True):
            st.markdown("##### Passo 4: Gradientes Finais");grad_w1,grad_w2,grad_bias=st.session_state.dE_dpred*st.session_state.dpred_dz*x[0],st.session_state.dE_dpred*st.session_state.dpred_dz*x[1],st.session_state.dE_dpred*st.session_state.dpred_dz*1.
            st.latex(r"\frac{\partial E}{\partial w_1}=(%.2f)\times(%.2f)\times(%.1f)=%.4f"%(dE_dpred,st.session_state.dpred_dz,x[0],grad_w1))
            st.latex(r"\frac{\partial E}{\partial w_2}=(%.2f)\times(%.2f)\times(%.1f)=%.4f"%(dE_dpred,st.session_state.dpred_dz,x[1],grad_w2))
            st.latex(r"\frac{\partial E}{\partial b}=(%.2f)\times(%.2f)\times(1)=%.4f"%(dE_dpred,st.session_state.dpred_dz,grad_bias))
            st.session_state.grad_w1,st.session_state.grad_w2,st.session_state.grad_bias=grad_w1,grad_w2,grad_bias
    if st.session_state.bp_step>=5:
        with st.container(border=True):
            st.markdown("##### Passo 5: Atualizar os Pesos - O Aprendizado Acontece!");st.success("Finalmente, ajustamos os pesos na direÃ§Ã£o OPOSTA ao gradiente, multiplicando pela taxa de aprendizado.")
            w_novo1,w_novo2,bias_novo=w[0]-learning_rate*st.session_state.grad_w1,w[1]-learning_rate*st.session_state.grad_w2,bias-learning_rate*st.session_state.grad_bias
            st.latex(r"w_{novo}=w_{antigo}-\eta\times\frac{\partial E}{\partial w}");st.markdown("**Novos Pesos:**");st.markdown(f"- `wâ‚_novo={w[0]:.2f}-{learning_rate}Ã—({st.session_state.grad_w1:.4f})={w_novo1:.4f}`\n- `wâ‚‚_novo={w[1]:.2f}-{learning_rate}Ã—({st.session_state.grad_w2:.4f})={w_novo2:.4f}`\n- `b_novo={bias:.2f}-{learning_rate}Ã—({st.session_state.grad_bias:.4f})={bias_novo:.4f}`")
            st.markdown("\nEstes seriam os novos pesos para o prÃ³ximo ciclo de treinamento!")
    if st.session_state.bp_step > 5: st.balloons();st.info("VocÃª completou um passo de backpropagation! Clique em 'Reiniciar' para ver o processo novamente com diferentes taxas de aprendizado.")